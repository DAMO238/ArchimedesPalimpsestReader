{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning to Read Palimpsests\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image,ImageDraw\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "\n",
    "class Character:\n",
    "    # first four variables give the line mappings, the char is the first character in the line and the file is the folder from which the data has come from\n",
    "    def __init__(self, lrx, lry, ulx, uly, char, file):\n",
    "        self.ulx = ulx\n",
    "        self.uly = uly\n",
    "        self.square_side_length = lry - uly\n",
    "        self.lrx = ulx + self.square_side_length\n",
    "        self.lry = uly + self.square_side_length\n",
    "        self.char = char\n",
    "        self.file = file\n",
    "        \n",
    "    def display(self):\n",
    "        im = Image.open(self.file)\n",
    "        drawer = ImageDraw.Draw(im)\n",
    "        drawer.rectangle((self.ulx,self.uly,self.lrx,self.lry), outline=(255,0,0), width=5)\n",
    "        return im\n",
    "        \n",
    "    def crop(self, show=False, resize=0):\n",
    "        im = Image.open(self.file)\n",
    "        im = im.crop((self.ulx, self.uly, self.lrx, self.lry))\n",
    "        if resize != 0:\n",
    "            im = im.resize((resize,resize))\n",
    "        if show:\n",
    "            im.show()\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Display Method\n",
    "# Expected result: square box around tau in top left of palimpsest\n",
    "\n",
    "char = Character(3900, 4422, 1780, 4230, \"τ\", \"data/Archimedes/Data/0000-100r/0000-100r_Arch53v_Sinar_LED470_01_pack8.tif\")\n",
    "im = char.display()\n",
    "drawer = ImageDraw.Draw(im)\n",
    "drawer.rectangle((3900, 4422, 1780, 4230), outline=(0,255,0), width=5)\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Crop Method\n",
    "# Expected result: tau that looks identical to the one in the box above in a lower resolution\n",
    "\n",
    "char = Character(3900, 4422, 1780, 4230, \"τ\", \"data/Archimedes/Data/0000-100r/0000-100r_Arch53v_Sinar_LED470_01_pack8.tif\")\n",
    "char.crop(resize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone Functions for Extracting Dataset\n",
    "\n",
    "def extract_char_locations(data, path):\n",
    "    with open(path, 'r') as f:\n",
    "        tei = f.read()\n",
    "        lines = tei.split('\\n')\n",
    "        line_mappings = []\n",
    "        counter = 1\n",
    "        for line in lines:\n",
    "            if \"zone\" in line:\n",
    "                parts = line.split('\"')\n",
    "                line_mappings.append([int(parts[1]), int(parts[3]), int(parts[5]), int(parts[7])])\n",
    "        milestone_locations = (tei.find(\"milestone\"), tei.rfind(\"milestone\"))\n",
    "        flip = False\n",
    "        for i in range(len(line_mappings)+1):\n",
    "            loc = -1\n",
    "            if not flip:\n",
    "                loc = tei.find(f'n=\"{counter}\"')\n",
    "                if loc > milestone_locations[1] or loc == -1:\n",
    "                    counter = 1\n",
    "                    flip = True\n",
    "                    continue\n",
    "            else:\n",
    "                loc = tei.find(f'n=\"{counter}\"')\n",
    "            char_loc = tei.find('>', loc)+1\n",
    "            char = tei[char_loc:char_loc+1]\n",
    "            if not char == '<':\n",
    "                data.append(line_mappings[0] + [char, []])\n",
    "            try:\n",
    "                del line_mappings[0]\n",
    "            except:\n",
    "                return\n",
    "            counter += 1\n",
    "                \n",
    "\n",
    "        \n",
    "        \n",
    "def get_characters(folder):\n",
    "    data = []\n",
    "    with os.scandir(\"/home/damien/Jupyter/data/Archimedes/Data/\" + folder) as files:\n",
    "        for file in files:\n",
    "            if \"TEI\" in file.name and not \"md5\" in file.name:\n",
    "                extract_char_locations(data, \"/home/damien/Jupyter/data/Archimedes/Data/\" + folder + '/' + file.name)\n",
    "    file_list = []\n",
    "    with os.scandir(\"/home/damien/Jupyter/data/Archimedes/Data/\" + folder) as files:\n",
    "        for file in files:\n",
    "            if \"LED\" in file.name and \"tif\" in file.name:\n",
    "                file_list.append(file.name)\n",
    "    file_list.sort()\n",
    "    for file in file_list:\n",
    "        print(file)\n",
    "        for chars in data:\n",
    "            char = Character(chars[0], chars[1], chars[2], chars[3], chars[4], \"/home/damien/Jupyter/data/Archimedes/Data/\" + folder + '/' + file)\n",
    "            chars[5].append(np.asarray(char.crop(resize=32)))\n",
    "    for chars in data:\n",
    "        chars[5] = np.asarray(chars[5])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing above functions\n",
    "# Expected Result: Array of arrays of the location and character of the first characters in each line\n",
    "# followed by the same with numpy data of the image.\n",
    "\n",
    "data = []\n",
    "extract_char_locations(data, \"data/Archimedes/Data/0000-100r/0000-100r_Arch53v_TEI_Netz-Wilson.xml\")\n",
    "print(data)\n",
    "\n",
    "data = get_characters(\"170v-163r\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a Dataset\n",
    "\n",
    "!mkdir /home/damien/Jupyter/data/Archimedes/resized\n",
    "!mkdir /home/damien/Jupyter/data/Archimedes/resized/train\n",
    "!mkdir /home/damien/Jupyter/data/Archimedes/resized/validation\n",
    "!mkdir /home/damien/Jupyter/data/Archimedes/resized/test\n",
    "\n",
    "cum_splits = (0.5, 0.8, 1.0)\n",
    "sub_folders = (\"train/\", \"validation/\", \"test/\")\n",
    "\n",
    "folders = []\n",
    "    \n",
    "\n",
    "with os.scandir(\"/home/damien/Jupyter/data/Archimedes/Data\") as dirs:\n",
    "    for folder in dirs:\n",
    "        if not folder.is_file():\n",
    "            folders.append(folder.name)\n",
    "folders.sort()\n",
    "for folder in folders:\n",
    "    if folder == \"cambridge\" or folder == \"schema\" or folder == \"170v-163r\":\n",
    "        continue\n",
    "    print(folder)\n",
    "    data = get_characters(folder)\n",
    "    for i, char in enumerate(data):\n",
    "        sub_folder = random.choices(sub_folders, cum_weights=cum_splits, k=1)[0]\n",
    "        np.save(\"data/Archimedes/resized/\" + sub_folder + char[4] + str(i) + folder, char[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data back in for training\n",
    "# This can all be loaded into memory now, since we have cropped and resized all the images!\n",
    "\n",
    "train_data = []\n",
    "train_labs = []\n",
    "\n",
    "val_data = []\n",
    "val_labs = []\n",
    "\n",
    "test_data = []\n",
    "test_labs = []\n",
    "\n",
    "with os.scandir(\"data/Archimedes/resized/train\") as files:\n",
    "    for file in files:\n",
    "        print(file.name)\n",
    "        train_labs.append(file.name[:1])\n",
    "        train_data.append(np.load(\"data/Archimedes/resized/train/\" + file.name))\n",
    "    train_data = np.asarray(train_data)\n",
    "\n",
    "with os.scandir(\"data/Archimedes/resized/test\") as files:\n",
    "    for file in files:\n",
    "        print(file.name)\n",
    "        test_labs.append(file.name[:1])\n",
    "        test_data.append(np.load(\"data/Archimedes/resized/test/\" + file.name))\n",
    "    test_data = np.asarray(test_data)\n",
    "\n",
    "with os.scandir(\"data/Archimedes/resized/validation\") as files:\n",
    "    for file in files:\n",
    "        print(file.name)\n",
    "        val_labs.append(file.name[:1])\n",
    "        val_data.append(np.load(\"data/Archimedes/resized/validation/\" + file.name))\n",
    "    val_data = np.asarray(val_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make categories into numbers\n",
    "\n",
    "total_labs = (train_labs, test_labs, val_labs)\n",
    "conversion_dict = {}\n",
    "reverse_dict = {}\n",
    "\n",
    "for labs in total_labs:\n",
    "    for lab in labs:\n",
    "        if lab not in conversion_dict:\n",
    "            conversion_dict[lab] = len(conversion_dict)\n",
    "            reverse_dict[len(conversion_dict) - 1] = lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_labs(labs, reverse=False):\n",
    "    dic = reverse_dict if reverse else conversion_dict\n",
    "    tmp = []\n",
    "    for lab in labs:\n",
    "        tmp.append(dic[lab])\n",
    "    return np.asarray(tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot check data\n",
    "\n",
    "def spot_check(subset):\n",
    "    data = None\n",
    "    lab = None\n",
    "    if subset == \"train\":\n",
    "        data = random.choice(train_data)\n",
    "        lab = random.choice(train_labs)\n",
    "    elif subset == \"val\" or subset == \"validation\":\n",
    "        data = random.choice(val_data)\n",
    "        lab = random.choice(val_labs)\n",
    "    elif subset == \"test\":\n",
    "        data = random.choice(test_data)\n",
    "        lab = random.choice(test_labs)\n",
    "    else:\n",
    "        raise ValueException('Subset must be \"train\", \"val\"/\"validation\" or \"test\"!')\n",
    "    \n",
    "    print('Letter: ' + str(lab))\n",
    "    return Image.fromarray(random.choice(data), 'RGB')\n",
    "                           \n",
    "                           \n",
    "def spot_check_all(subset):\n",
    "    data = None\n",
    "    lab = None\n",
    "    if subset == \"train\":\n",
    "        data = random.choice(train_data)\n",
    "        lab = random.choice(train_labs)\n",
    "    elif subset == \"val\" or subset == \"validation\":\n",
    "        data = random.choice(val_data)\n",
    "        lab = random.choice(val_labs)\n",
    "    elif subset == \"test\":\n",
    "        data = random.choice(test_data)\n",
    "        lab = random.choice(test_labs)\n",
    "    else:\n",
    "        raise ValueException('Subset must be \"train\", \"val\"/\"validation\" or \"test\"!')\n",
    "    \n",
    "    print('Letter: ' + str(lab))\n",
    "    return Image.fromarray(random.choice(data), 'RGB')\n",
    "                           \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spot_check('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setback\n",
    "\n",
    "Unfortunately, running this check shows us that the line mappings are not a precise as I hoped. This means that some of the images do not contain the letter that we are looking for. We therefore expect to see a lower accuracy model at the end of this. However, if we do see an improvement in the accuracy and a drop in the loss, then we will have a proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_1 (Rescaling)      (None, 11, 32, 32, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 11, 30, 30, 4)     112       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 11, 15, 15, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 11, 13, 13, 12)    444       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 11, 6, 6, 12)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 6, 6, 12)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4752)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2433536   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 84)                43092     \n",
      "=================================================================\n",
      "Total params: 2,477,184\n",
      "Trainable params: 2,477,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(11,32,32,3,)))\n",
    "#model.add(tf.keras.layers.experimental.preprocessing.RandomRotation(0.1))\n",
    "#model.add(tf.keras.layers.experimental.preprocessing.RandomZoom(0.1))\n",
    "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255))\n",
    "#model.add(tf.keras.layers.Lambda(lambda x : x * (1 - 0.1*random.random())))\n",
    "model.add(tf.keras.layers.Conv3D(4, (1,3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling3D((1,2,2)))\n",
    "model.add(tf.keras.layers.Conv3D(12, (1,3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling3D((1,2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512))\n",
    "model.add(tf.keras.layers.Dense(len(conversion_dict.keys())))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', \n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs = convert_labs(train_labs)\n",
    "val_labs = convert_labs(val_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "458/458 [==============================] - 3s 6ms/step - loss: 3.5846 - accuracy: 0.2531 - val_loss: 3.3267 - val_accuracy: 0.2462\n",
      "Epoch 2/5\n",
      "458/458 [==============================] - 3s 6ms/step - loss: 3.2114 - accuracy: 0.2557 - val_loss: 3.3441 - val_accuracy: 0.2446\n",
      "Epoch 3/5\n",
      "458/458 [==============================] - 3s 6ms/step - loss: 3.0733 - accuracy: 0.2709 - val_loss: 3.4449 - val_accuracy: 0.2439\n",
      "Epoch 4/5\n",
      "458/458 [==============================] - 3s 6ms/step - loss: 2.8245 - accuracy: 0.2974 - val_loss: 3.4163 - val_accuracy: 0.2271\n",
      "Epoch 5/5\n",
      "458/458 [==============================] - 3s 6ms/step - loss: 2.5009 - accuracy: 0.3313 - val_loss: 3.7438 - val_accuracy: 0.1904\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(train_data, train_labs, batch_size=5, epochs = 5, validation_data=(val_data, val_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = fit.history['accuracy']\n",
    "val_acc = fit.history['val_accuracy']\n",
    "\n",
    "loss = fit.history['loss']\n",
    "val_loss = fit.history['val_loss']\n",
    "\n",
    "epochs_range = range(5)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.rcParams['font.size'] = 18\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "#plt.savefig('data/Archimedes/Output/lmla.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on testing data\n",
    "\n",
    "index = random.randint(0,len(test_labs))\n",
    "\n",
    "input_data = tf.expand_dims(test_data[index], 0)\n",
    "predictions = model.predict(input_data)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\"This image is predicted to be a {} with {:.2f} percent confidence.\".format(reverse_dict[np.argmax(score)], 100 * np.max(score)))\n",
    "print(\"This image was actually a {}\".format(test_labs[index]))\n",
    "\n",
    "\n",
    "Image.fromarray(random.choice(test_data[index]), 'RGB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
